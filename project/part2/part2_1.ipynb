{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b7b83ecc-217f-4839-a564-6b3375cc7bc1",
   "metadata": {},
   "source": [
    "# Part 2 VGG16 4bit weight, 2 bit activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f9c69520-88f2-4800-baec-7b35891f6110",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Building model...\n",
      "VGG_quant(\n",
      "  (features): Sequential(\n",
      "    (0): QuantConv2d(\n",
      "      3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "      (weight_quant): weight_quantize_fn()\n",
      "    )\n",
      "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "    (3): QuantConv2d(\n",
      "      64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "      (weight_quant): weight_quantize_fn()\n",
      "    )\n",
      "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (5): ReLU(inplace=True)\n",
      "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (7): QuantConv2d(\n",
      "      64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "      (weight_quant): weight_quantize_fn()\n",
      "    )\n",
      "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (9): ReLU(inplace=True)\n",
      "    (10): QuantConv2d(\n",
      "      128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "      (weight_quant): weight_quantize_fn()\n",
      "    )\n",
      "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (12): ReLU(inplace=True)\n",
      "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (14): QuantConv2d(\n",
      "      128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "      (weight_quant): weight_quantize_fn()\n",
      "    )\n",
      "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (16): ReLU(inplace=True)\n",
      "    (17): QuantConv2d(\n",
      "      256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "      (weight_quant): weight_quantize_fn()\n",
      "    )\n",
      "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (19): ReLU(inplace=True)\n",
      "    (20): QuantConv2d(\n",
      "      256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "      (weight_quant): weight_quantize_fn()\n",
      "    )\n",
      "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (22): ReLU(inplace=True)\n",
      "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (24): QuantConv2d(\n",
      "      256, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "      (weight_quant): weight_quantize_fn()\n",
      "    )\n",
      "    (25): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (26): ReLU(inplace=True)\n",
      "    (27): QuantConv2d(\n",
      "      16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "      (weight_quant): weight_quantize_fn()\n",
      "    )\n",
      "    (28): ReLU(inplace=True)\n",
      "    (29): QuantConv2d(\n",
      "      16, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "      (weight_quant): weight_quantize_fn()\n",
      "    )\n",
      "    (30): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (31): ReLU(inplace=True)\n",
      "    (32): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (33): QuantConv2d(\n",
      "      512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "      (weight_quant): weight_quantize_fn()\n",
      "    )\n",
      "    (34): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (35): ReLU(inplace=True)\n",
      "    (36): QuantConv2d(\n",
      "      512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "      (weight_quant): weight_quantize_fn()\n",
      "    )\n",
      "    (37): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (38): ReLU(inplace=True)\n",
      "    (39): QuantConv2d(\n",
      "      512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "      (weight_quant): weight_quantize_fn()\n",
      "    )\n",
      "    (40): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (41): ReLU(inplace=True)\n",
      "    (42): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (43): AvgPool2d(kernel_size=1, stride=1, padding=0)\n",
      "  )\n",
      "  (classifier): Linear(in_features=512, out_features=10, bias=True)\n",
      ")\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import os\n",
    "import time\n",
    "import shutil\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torch.backends.cudnn as cudnn\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# Include parent dir in path\n",
    "import sys\n",
    "from pathlib import Path\n",
    "parent_dir = str(Path.cwd().parent)\n",
    "if parent_dir not in sys.path:\n",
    "    sys.path.append(parent_dir)\n",
    "\n",
    "from models import *\n",
    "import math\n",
    "\n",
    "global best_prec\n",
    "use_gpu = torch.cuda.is_available()\n",
    "print('=> Building model...')\n",
    "    \n",
    "    \n",
    "batch_size = 128\n",
    "model_name = \"VGG16_project_part2\"\n",
    "model = VGG(vgg_name=model_name, w_bits=4, a_bits=2)\n",
    "print(model)\n",
    "\n",
    "normalize = transforms.Normalize(mean=[0.491, 0.482, 0.447], std=[0.247, 0.243, 0.262])\n",
    "\n",
    "\n",
    "train_dataset = torchvision.datasets.CIFAR10(\n",
    "    root='../data',\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=transforms.Compose([\n",
    "        transforms.RandomCrop(32, padding=4),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        normalize,\n",
    "    ]))\n",
    "trainloader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "\n",
    "\n",
    "test_dataset = torchvision.datasets.CIFAR10(\n",
    "    root='../data',\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        normalize,\n",
    "    ]))\n",
    "\n",
    "testloader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
    "\n",
    "\n",
    "print_freq = 100 # every 100 batches, accuracy printed. Here, each batch includes \"batch_size\" data points\n",
    "# CIFAR10 has 50,000 training data, and 10,000 validation data.\n",
    "\n",
    "def train(trainloader, model, criterion, optimizer, epoch):\n",
    "    batch_time = AverageMeter()\n",
    "    data_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "    top1 = AverageMeter()\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    end = time.time()\n",
    "    for i, (input, target) in enumerate(trainloader):\n",
    "        # measure data loading time\n",
    "        data_time.update(time.time() - end)\n",
    "\n",
    "        input, target = input.cuda(), target.cuda()\n",
    "\n",
    "        # compute output\n",
    "        output = model(input)\n",
    "        loss = criterion(output, target)\n",
    "\n",
    "        # measure accuracy and record loss\n",
    "        prec = accuracy(output, target)[0]\n",
    "        losses.update(loss.item(), input.size(0))\n",
    "        top1.update(prec.item(), input.size(0))\n",
    "\n",
    "        # compute gradient and do SGD step\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # measure elapsed time\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "\n",
    "\n",
    "        if i % print_freq == 0:\n",
    "            print('Epoch: [{0}][{1}/{2}]\\t'\n",
    "                  'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t'\n",
    "                  'Data {data_time.val:.3f} ({data_time.avg:.3f})\\t'\n",
    "                  'Loss {loss.val:.4f} ({loss.avg:.4f})\\t'\n",
    "                  'Prec {top1.val:.3f}% ({top1.avg:.3f}%)'.format(\n",
    "                   epoch, i, len(trainloader), batch_time=batch_time,\n",
    "                   data_time=data_time, loss=losses, top1=top1))\n",
    "\n",
    "            \n",
    "\n",
    "def validate(val_loader, model, criterion ):\n",
    "    batch_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "    top1 = AverageMeter()\n",
    "\n",
    "    # switch to evaluate mode\n",
    "    model.eval()\n",
    "\n",
    "    end = time.time()\n",
    "    with torch.no_grad():\n",
    "        for i, (input, target) in enumerate(val_loader):\n",
    "         \n",
    "            input, target = input.cuda(), target.cuda()\n",
    "\n",
    "            # compute output\n",
    "            output = model(input)\n",
    "            loss = criterion(output, target)\n",
    "\n",
    "            # measure accuracy and record loss\n",
    "            prec = accuracy(output, target)[0]\n",
    "            losses.update(loss.item(), input.size(0))\n",
    "            top1.update(prec.item(), input.size(0))\n",
    "\n",
    "            # measure elapsed time\n",
    "            batch_time.update(time.time() - end)\n",
    "            end = time.time()\n",
    "\n",
    "            if i % print_freq == 0:  # This line shows how frequently print out the status. e.g., i%5 => every 5 batch, prints out\n",
    "                print('Test: [{0}/{1}]\\t'\n",
    "                  'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t'\n",
    "                  'Loss {loss.val:.4f} ({loss.avg:.4f})\\t'\n",
    "                  'Prec {top1.val:.3f}% ({top1.avg:.3f}%)'.format(\n",
    "                   i, len(val_loader), batch_time=batch_time, loss=losses,\n",
    "                   top1=top1))\n",
    "\n",
    "    print(' * Prec {top1.avg:.3f}% '.format(top1=top1))\n",
    "    return top1.avg\n",
    "\n",
    "\n",
    "def accuracy(output, target, topk=(1,)):\n",
    "    \"\"\"Computes the precision@k for the specified values of k\"\"\"\n",
    "    maxk = max(topk)\n",
    "    batch_size = target.size(0)\n",
    "\n",
    "    _, pred = output.topk(maxk, 1, True, True)\n",
    "    pred = pred.t()\n",
    "    correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
    "\n",
    "    res = []\n",
    "    for k in topk:\n",
    "        correct_k = correct[:k].view(-1).float().sum(0)\n",
    "        res.append(correct_k.mul_(100.0 / batch_size))\n",
    "    return res\n",
    "\n",
    "\n",
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "        \n",
    "def save_checkpoint(state, is_best, fdir):\n",
    "    filepath = os.path.join(fdir, 'checkpoint.pth')\n",
    "    torch.save(state, filepath)\n",
    "    if is_best:\n",
    "        shutil.copyfile(filepath, os.path.join(fdir, 'model_best.pth.tar'))\n",
    "\n",
    "\n",
    "def adjust_learning_rate(optimizer, epoch):\n",
    "    \"\"\"For resnet, the lr starts from 0.1, and is divided by 10 at 80 and 120 epochs\"\"\"\n",
    "    adjust_list = [150, 225]\n",
    "    if epoch in adjust_list:\n",
    "        for param_group in optimizer.param_groups:\n",
    "            param_group['lr'] = param_group['lr'] * 0.1        \n",
    "\n",
    "#model = nn.DataParallel(model).cuda()\n",
    "#all_params = checkpoint['state_dict']\n",
    "#model.load_state_dict(all_params, strict=False)\n",
    "#criterion = nn.CrossEntropyLoss().cuda()\n",
    "#validate(testloader, model, criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3defdcfb-b794-47e3-bd37-66c6f1a05ed3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [0][0/391]\tTime 1.129 (1.129)\tData 0.599 (0.599)\tLoss 2.3939 (2.3939)\tPrec 9.375% (9.375%)\n",
      "Epoch: [0][100/391]\tTime 0.049 (0.056)\tData 0.002 (0.008)\tLoss 2.0356 (2.1893)\tPrec 19.531% (18.851%)\n",
      "Epoch: [0][200/391]\tTime 0.042 (0.051)\tData 0.001 (0.005)\tLoss 2.0513 (2.0916)\tPrec 23.438% (22.147%)\n",
      "Epoch: [0][300/391]\tTime 0.042 (0.048)\tData 0.001 (0.004)\tLoss 1.8280 (2.0316)\tPrec 29.688% (24.395%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.310 (0.310)\tLoss 2.0828 (2.0828)\tPrec 27.344% (27.344%)\n",
      " * Prec 29.060% \n",
      "best acc: 29.060000\n",
      "Epoch: [1][0/391]\tTime 0.706 (0.706)\tData 0.656 (0.656)\tLoss 1.8831 (1.8831)\tPrec 30.469% (30.469%)\n",
      "Epoch: [1][100/391]\tTime 0.047 (0.053)\tData 0.002 (0.010)\tLoss 1.8027 (1.8916)\tPrec 36.719% (30.972%)\n",
      "Epoch: [1][200/391]\tTime 0.042 (0.049)\tData 0.002 (0.006)\tLoss 1.7947 (1.8709)\tPrec 33.594% (32.097%)\n",
      "Epoch: [1][300/391]\tTime 0.047 (0.048)\tData 0.002 (0.004)\tLoss 1.9186 (1.8400)\tPrec 28.125% (33.319%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.523 (0.523)\tLoss 1.8519 (1.8519)\tPrec 38.281% (38.281%)\n",
      " * Prec 35.340% \n",
      "best acc: 35.340000\n",
      "Epoch: [2][0/391]\tTime 0.581 (0.581)\tData 0.529 (0.529)\tLoss 1.7231 (1.7231)\tPrec 36.719% (36.719%)\n",
      "Epoch: [2][100/391]\tTime 0.048 (0.052)\tData 0.002 (0.009)\tLoss 1.7245 (1.7628)\tPrec 38.281% (35.698%)\n",
      "Epoch: [2][200/391]\tTime 0.045 (0.049)\tData 0.002 (0.005)\tLoss 1.6849 (1.7495)\tPrec 35.938% (36.524%)\n",
      "Epoch: [2][300/391]\tTime 0.047 (0.048)\tData 0.002 (0.004)\tLoss 1.6628 (1.7295)\tPrec 44.531% (37.316%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.335 (0.335)\tLoss 1.7299 (1.7299)\tPrec 42.188% (42.188%)\n",
      " * Prec 38.570% \n",
      "best acc: 38.570000\n",
      "Epoch: [3][0/391]\tTime 0.645 (0.645)\tData 0.597 (0.597)\tLoss 1.6555 (1.6555)\tPrec 38.281% (38.281%)\n",
      "Epoch: [3][100/391]\tTime 0.047 (0.051)\tData 0.002 (0.008)\tLoss 1.5092 (1.6677)\tPrec 42.969% (39.968%)\n",
      "Epoch: [3][200/391]\tTime 0.043 (0.048)\tData 0.002 (0.005)\tLoss 1.7080 (1.6488)\tPrec 35.938% (40.551%)\n",
      "Epoch: [3][300/391]\tTime 0.047 (0.047)\tData 0.002 (0.004)\tLoss 1.5625 (1.6273)\tPrec 40.625% (41.380%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.559 (0.559)\tLoss 1.5742 (1.5742)\tPrec 42.969% (42.969%)\n",
      " * Prec 39.510% \n",
      "best acc: 39.510000\n",
      "Epoch: [4][0/391]\tTime 0.700 (0.700)\tData 0.648 (0.648)\tLoss 1.5183 (1.5183)\tPrec 46.094% (46.094%)\n",
      "Epoch: [4][100/391]\tTime 0.047 (0.052)\tData 0.002 (0.008)\tLoss 1.5292 (1.5714)\tPrec 48.438% (44.346%)\n",
      "Epoch: [4][200/391]\tTime 0.045 (0.049)\tData 0.002 (0.005)\tLoss 1.6707 (1.5609)\tPrec 39.844% (44.461%)\n",
      "Epoch: [4][300/391]\tTime 0.046 (0.048)\tData 0.001 (0.004)\tLoss 1.5869 (1.5489)\tPrec 38.281% (44.884%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.249 (0.249)\tLoss 1.3955 (1.3955)\tPrec 52.344% (52.344%)\n",
      " * Prec 45.850% \n",
      "best acc: 45.850000\n",
      "Epoch: [5][0/391]\tTime 0.581 (0.581)\tData 0.523 (0.523)\tLoss 1.5750 (1.5750)\tPrec 43.750% (43.750%)\n",
      "Epoch: [5][100/391]\tTime 0.049 (0.051)\tData 0.002 (0.007)\tLoss 1.4146 (1.5196)\tPrec 50.781% (45.838%)\n",
      "Epoch: [5][200/391]\tTime 0.047 (0.048)\tData 0.002 (0.005)\tLoss 1.3152 (1.5041)\tPrec 56.250% (46.564%)\n",
      "Epoch: [5][300/391]\tTime 0.045 (0.047)\tData 0.002 (0.004)\tLoss 1.5801 (1.4897)\tPrec 42.188% (47.067%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.360 (0.360)\tLoss 1.4121 (1.4121)\tPrec 50.000% (50.000%)\n",
      " * Prec 45.670% \n",
      "best acc: 45.850000\n",
      "Epoch: [6][0/391]\tTime 0.902 (0.902)\tData 0.851 (0.851)\tLoss 1.4302 (1.4302)\tPrec 46.875% (46.875%)\n",
      "Epoch: [6][100/391]\tTime 0.047 (0.054)\tData 0.002 (0.010)\tLoss 1.2868 (1.4315)\tPrec 55.469% (49.018%)\n",
      "Epoch: [6][200/391]\tTime 0.047 (0.050)\tData 0.002 (0.006)\tLoss 1.5345 (1.4252)\tPrec 45.312% (49.370%)\n",
      "Epoch: [6][300/391]\tTime 0.048 (0.048)\tData 0.002 (0.005)\tLoss 1.4225 (1.4212)\tPrec 50.781% (49.766%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.251 (0.251)\tLoss 1.4201 (1.4201)\tPrec 48.438% (48.438%)\n",
      " * Prec 43.430% \n",
      "best acc: 45.850000\n",
      "Epoch: [7][0/391]\tTime 0.845 (0.845)\tData 0.793 (0.793)\tLoss 1.4382 (1.4382)\tPrec 51.562% (51.562%)\n",
      "Epoch: [7][100/391]\tTime 0.048 (0.053)\tData 0.002 (0.010)\tLoss 1.3466 (1.3504)\tPrec 53.125% (52.019%)\n",
      "Epoch: [7][200/391]\tTime 0.043 (0.049)\tData 0.003 (0.006)\tLoss 1.3681 (1.3642)\tPrec 54.688% (51.500%)\n",
      "Epoch: [7][300/391]\tTime 0.047 (0.048)\tData 0.002 (0.004)\tLoss 1.3536 (1.3630)\tPrec 53.125% (51.601%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.378 (0.378)\tLoss 1.3912 (1.3912)\tPrec 54.688% (54.688%)\n",
      " * Prec 49.040% \n",
      "best acc: 49.040000\n",
      "Epoch: [8][0/391]\tTime 0.571 (0.571)\tData 0.527 (0.527)\tLoss 1.3245 (1.3245)\tPrec 53.906% (53.906%)\n",
      "Epoch: [8][100/391]\tTime 0.043 (0.050)\tData 0.002 (0.007)\tLoss 1.5041 (1.3514)\tPrec 42.188% (51.779%)\n",
      "Epoch: [8][200/391]\tTime 0.047 (0.048)\tData 0.002 (0.004)\tLoss 1.2361 (1.3356)\tPrec 60.938% (52.425%)\n",
      "Epoch: [8][300/391]\tTime 0.047 (0.047)\tData 0.001 (0.004)\tLoss 1.4233 (1.3362)\tPrec 54.688% (52.525%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.239 (0.239)\tLoss 1.2185 (1.2185)\tPrec 53.125% (53.125%)\n",
      " * Prec 53.950% \n",
      "best acc: 53.950000\n",
      "Epoch: [9][0/391]\tTime 0.488 (0.488)\tData 0.447 (0.447)\tLoss 1.2835 (1.2835)\tPrec 54.688% (54.688%)\n",
      "Epoch: [9][100/391]\tTime 0.045 (0.048)\tData 0.002 (0.006)\tLoss 1.1931 (1.3022)\tPrec 59.375% (53.875%)\n",
      "Epoch: [9][200/391]\tTime 0.047 (0.047)\tData 0.002 (0.004)\tLoss 1.2038 (1.3007)\tPrec 57.812% (53.984%)\n",
      "Epoch: [9][300/391]\tTime 0.046 (0.046)\tData 0.002 (0.003)\tLoss 1.2249 (1.2959)\tPrec 58.594% (54.166%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.254 (0.254)\tLoss 1.3831 (1.3831)\tPrec 52.344% (52.344%)\n",
      " * Prec 52.470% \n",
      "best acc: 53.950000\n",
      "Epoch: [10][0/391]\tTime 0.773 (0.773)\tData 0.720 (0.720)\tLoss 1.1063 (1.1063)\tPrec 61.719% (61.719%)\n",
      "Epoch: [10][100/391]\tTime 0.045 (0.053)\tData 0.002 (0.009)\tLoss 1.2262 (1.2924)\tPrec 60.156% (54.765%)\n",
      "Epoch: [10][200/391]\tTime 0.048 (0.049)\tData 0.002 (0.005)\tLoss 1.3056 (1.2836)\tPrec 55.469% (54.827%)\n",
      "Epoch: [10][300/391]\tTime 0.047 (0.048)\tData 0.002 (0.004)\tLoss 1.1445 (1.2788)\tPrec 57.812% (54.906%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.253 (0.253)\tLoss 1.3577 (1.3577)\tPrec 53.906% (53.906%)\n",
      " * Prec 50.320% \n",
      "best acc: 53.950000\n",
      "Epoch: [11][0/391]\tTime 0.597 (0.597)\tData 0.550 (0.550)\tLoss 1.4826 (1.4826)\tPrec 50.000% (50.000%)\n",
      "Epoch: [11][100/391]\tTime 0.044 (0.051)\tData 0.002 (0.007)\tLoss 1.3505 (1.2505)\tPrec 47.656% (55.995%)\n",
      "Epoch: [11][200/391]\tTime 0.045 (0.048)\tData 0.002 (0.004)\tLoss 1.3389 (1.2465)\tPrec 55.469% (56.133%)\n",
      "Epoch: [11][300/391]\tTime 0.045 (0.047)\tData 0.002 (0.004)\tLoss 1.3279 (1.2477)\tPrec 53.125% (56.112%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.284 (0.284)\tLoss 1.2378 (1.2378)\tPrec 59.375% (59.375%)\n",
      " * Prec 53.240% \n",
      "best acc: 53.950000\n",
      "Epoch: [12][0/391]\tTime 0.619 (0.619)\tData 0.563 (0.563)\tLoss 1.1326 (1.1326)\tPrec 53.125% (53.125%)\n",
      "Epoch: [12][100/391]\tTime 0.045 (0.052)\tData 0.002 (0.008)\tLoss 1.3288 (1.2192)\tPrec 59.375% (57.225%)\n",
      "Epoch: [12][200/391]\tTime 0.042 (0.049)\tData 0.002 (0.005)\tLoss 1.1725 (1.2224)\tPrec 60.156% (56.611%)\n",
      "Epoch: [12][300/391]\tTime 0.045 (0.048)\tData 0.002 (0.004)\tLoss 1.2244 (1.2237)\tPrec 55.469% (56.792%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.247 (0.247)\tLoss 1.2270 (1.2270)\tPrec 54.688% (54.688%)\n",
      " * Prec 54.490% \n",
      "best acc: 54.490000\n",
      "Epoch: [13][0/391]\tTime 0.623 (0.623)\tData 0.573 (0.573)\tLoss 1.1040 (1.1040)\tPrec 60.938% (60.938%)\n",
      "Epoch: [13][100/391]\tTime 0.046 (0.051)\tData 0.002 (0.007)\tLoss 1.2354 (1.1961)\tPrec 54.688% (57.789%)\n",
      "Epoch: [13][200/391]\tTime 0.045 (0.048)\tData 0.002 (0.005)\tLoss 1.3520 (1.1977)\tPrec 53.125% (57.945%)\n",
      "Epoch: [13][300/391]\tTime 0.047 (0.047)\tData 0.002 (0.004)\tLoss 1.4290 (1.2010)\tPrec 53.125% (57.859%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.447 (0.447)\tLoss 1.1251 (1.1251)\tPrec 66.406% (66.406%)\n",
      " * Prec 56.220% \n",
      "best acc: 56.220000\n",
      "Epoch: [14][0/391]\tTime 0.498 (0.498)\tData 0.448 (0.448)\tLoss 1.1634 (1.1634)\tPrec 64.062% (64.062%)\n",
      "Epoch: [14][100/391]\tTime 0.046 (0.050)\tData 0.002 (0.006)\tLoss 1.2901 (1.1921)\tPrec 53.906% (57.944%)\n",
      "Epoch: [14][200/391]\tTime 0.046 (0.047)\tData 0.002 (0.004)\tLoss 1.2334 (1.1832)\tPrec 57.031% (58.465%)\n",
      "Epoch: [14][300/391]\tTime 0.047 (0.047)\tData 0.002 (0.003)\tLoss 0.9795 (1.1802)\tPrec 67.969% (58.627%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.337 (0.337)\tLoss 1.1390 (1.1390)\tPrec 60.156% (60.156%)\n",
      " * Prec 56.640% \n",
      "best acc: 56.640000\n",
      "Epoch: [15][0/391]\tTime 0.920 (0.920)\tData 0.872 (0.872)\tLoss 1.0474 (1.0474)\tPrec 64.062% (64.062%)\n",
      "Epoch: [15][100/391]\tTime 0.045 (0.054)\tData 0.002 (0.011)\tLoss 1.1982 (1.1350)\tPrec 59.375% (60.705%)\n",
      "Epoch: [15][200/391]\tTime 0.043 (0.050)\tData 0.002 (0.006)\tLoss 1.1099 (1.1424)\tPrec 64.844% (60.098%)\n",
      "Epoch: [15][300/391]\tTime 0.044 (0.049)\tData 0.002 (0.005)\tLoss 1.1688 (1.1471)\tPrec 53.906% (59.889%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.247 (0.247)\tLoss 1.2196 (1.2196)\tPrec 57.031% (57.031%)\n",
      " * Prec 56.460% \n",
      "best acc: 56.640000\n",
      "Epoch: [16][0/391]\tTime 0.614 (0.614)\tData 0.565 (0.565)\tLoss 1.1580 (1.1580)\tPrec 60.156% (60.156%)\n",
      "Epoch: [16][100/391]\tTime 0.046 (0.052)\tData 0.002 (0.007)\tLoss 1.2625 (1.1439)\tPrec 55.469% (59.769%)\n",
      "Epoch: [16][200/391]\tTime 0.044 (0.049)\tData 0.002 (0.005)\tLoss 1.1636 (1.1408)\tPrec 60.938% (59.904%)\n",
      "Epoch: [16][300/391]\tTime 0.043 (0.048)\tData 0.002 (0.004)\tLoss 1.0851 (1.1408)\tPrec 62.500% (59.920%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.236 (0.236)\tLoss 1.2281 (1.2281)\tPrec 57.031% (57.031%)\n",
      " * Prec 57.170% \n",
      "best acc: 57.170000\n",
      "Epoch: [17][0/391]\tTime 0.825 (0.825)\tData 0.777 (0.777)\tLoss 1.0828 (1.0828)\tPrec 61.719% (61.719%)\n",
      "Epoch: [17][100/391]\tTime 0.046 (0.053)\tData 0.002 (0.010)\tLoss 1.1709 (1.0899)\tPrec 63.281% (62.167%)\n",
      "Epoch: [17][200/391]\tTime 0.041 (0.049)\tData 0.002 (0.006)\tLoss 1.4516 (1.1130)\tPrec 51.562% (61.392%)\n",
      "Epoch: [17][300/391]\tTime 0.047 (0.048)\tData 0.002 (0.004)\tLoss 1.0201 (1.1145)\tPrec 62.500% (61.262%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.272 (0.272)\tLoss 1.1555 (1.1555)\tPrec 55.469% (55.469%)\n",
      " * Prec 58.510% \n",
      "best acc: 58.510000\n",
      "Epoch: [18][0/391]\tTime 0.993 (0.993)\tData 0.941 (0.941)\tLoss 1.1814 (1.1814)\tPrec 59.375% (59.375%)\n",
      "Epoch: [18][100/391]\tTime 0.048 (0.055)\tData 0.002 (0.011)\tLoss 1.0913 (1.0804)\tPrec 60.156% (62.082%)\n",
      "Epoch: [18][200/391]\tTime 0.043 (0.050)\tData 0.002 (0.006)\tLoss 1.0832 (1.0867)\tPrec 56.250% (62.275%)\n",
      "Epoch: [18][300/391]\tTime 0.042 (0.048)\tData 0.002 (0.005)\tLoss 1.1408 (1.0886)\tPrec 61.719% (62.087%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.444 (0.444)\tLoss 1.0874 (1.0874)\tPrec 60.156% (60.156%)\n",
      " * Prec 58.690% \n",
      "best acc: 58.690000\n",
      "Epoch: [19][0/391]\tTime 0.628 (0.628)\tData 0.579 (0.579)\tLoss 1.1199 (1.1199)\tPrec 60.938% (60.938%)\n",
      "Epoch: [19][100/391]\tTime 0.045 (0.051)\tData 0.002 (0.007)\tLoss 1.2589 (1.0889)\tPrec 54.688% (61.618%)\n",
      "Epoch: [19][200/391]\tTime 0.046 (0.048)\tData 0.002 (0.005)\tLoss 1.1305 (1.0823)\tPrec 62.500% (62.049%)\n",
      "Epoch: [19][300/391]\tTime 0.048 (0.047)\tData 0.002 (0.004)\tLoss 1.1169 (1.0824)\tPrec 60.938% (62.087%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.264 (0.264)\tLoss 1.0179 (1.0179)\tPrec 64.062% (64.062%)\n",
      " * Prec 59.420% \n",
      "best acc: 59.420000\n",
      "Epoch: [20][0/391]\tTime 0.709 (0.709)\tData 0.655 (0.655)\tLoss 1.2438 (1.2438)\tPrec 53.906% (53.906%)\n",
      "Epoch: [20][100/391]\tTime 0.042 (0.052)\tData 0.002 (0.008)\tLoss 1.0743 (1.0592)\tPrec 58.594% (62.956%)\n",
      "Epoch: [20][200/391]\tTime 0.047 (0.049)\tData 0.002 (0.005)\tLoss 0.9108 (1.0644)\tPrec 64.844% (62.850%)\n",
      "Epoch: [20][300/391]\tTime 0.043 (0.047)\tData 0.002 (0.004)\tLoss 1.0934 (1.0676)\tPrec 57.031% (62.687%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.450 (0.450)\tLoss 1.1632 (1.1632)\tPrec 61.719% (61.719%)\n",
      " * Prec 58.210% \n",
      "best acc: 59.420000\n",
      "Epoch: [21][0/391]\tTime 0.739 (0.739)\tData 0.689 (0.689)\tLoss 0.9943 (0.9943)\tPrec 63.281% (63.281%)\n",
      "Epoch: [21][100/391]\tTime 0.045 (0.052)\tData 0.002 (0.009)\tLoss 0.9570 (1.0403)\tPrec 62.500% (63.815%)\n",
      "Epoch: [21][200/391]\tTime 0.048 (0.049)\tData 0.002 (0.005)\tLoss 0.9977 (1.0401)\tPrec 64.844% (63.763%)\n",
      "Epoch: [21][300/391]\tTime 0.048 (0.048)\tData 0.002 (0.004)\tLoss 0.9415 (1.0446)\tPrec 69.531% (63.676%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.529 (0.529)\tLoss 1.1904 (1.1904)\tPrec 59.375% (59.375%)\n",
      " * Prec 59.350% \n",
      "best acc: 59.420000\n",
      "Epoch: [22][0/391]\tTime 0.556 (0.556)\tData 0.507 (0.507)\tLoss 1.0883 (1.0883)\tPrec 60.938% (60.938%)\n",
      "Epoch: [22][100/391]\tTime 0.043 (0.050)\tData 0.002 (0.007)\tLoss 1.1207 (1.0333)\tPrec 59.375% (63.993%)\n",
      "Epoch: [22][200/391]\tTime 0.047 (0.048)\tData 0.003 (0.004)\tLoss 1.1364 (1.0259)\tPrec 60.156% (64.420%)\n",
      "Epoch: [22][300/391]\tTime 0.049 (0.047)\tData 0.001 (0.003)\tLoss 1.0346 (1.0308)\tPrec 67.188% (64.161%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.347 (0.347)\tLoss 1.0572 (1.0572)\tPrec 63.281% (63.281%)\n",
      " * Prec 60.990% \n",
      "best acc: 60.990000\n",
      "Epoch: [23][0/391]\tTime 0.583 (0.583)\tData 0.514 (0.514)\tLoss 0.8820 (0.8820)\tPrec 68.750% (68.750%)\n",
      "Epoch: [23][100/391]\tTime 0.044 (0.051)\tData 0.002 (0.007)\tLoss 0.8829 (0.9992)\tPrec 71.094% (65.432%)\n",
      "Epoch: [23][200/391]\tTime 0.047 (0.048)\tData 0.002 (0.004)\tLoss 0.9175 (1.0038)\tPrec 75.781% (65.333%)\n",
      "Epoch: [23][300/391]\tTime 0.046 (0.047)\tData 0.002 (0.003)\tLoss 1.0539 (1.0130)\tPrec 59.375% (64.823%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.255 (0.255)\tLoss 1.1100 (1.1100)\tPrec 59.375% (59.375%)\n",
      " * Prec 61.050% \n",
      "best acc: 61.050000\n",
      "Epoch: [24][0/391]\tTime 0.521 (0.521)\tData 0.463 (0.463)\tLoss 0.9732 (0.9732)\tPrec 67.188% (67.188%)\n",
      "Epoch: [24][100/391]\tTime 0.045 (0.050)\tData 0.002 (0.007)\tLoss 1.0484 (0.9937)\tPrec 62.500% (65.022%)\n",
      "Epoch: [24][200/391]\tTime 0.044 (0.048)\tData 0.002 (0.004)\tLoss 1.0771 (0.9911)\tPrec 61.719% (65.271%)\n",
      "Epoch: [24][300/391]\tTime 0.046 (0.047)\tData 0.001 (0.003)\tLoss 0.9096 (0.9958)\tPrec 66.406% (65.275%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.419 (0.419)\tLoss 1.0371 (1.0371)\tPrec 66.406% (66.406%)\n",
      " * Prec 62.360% \n",
      "best acc: 62.360000\n",
      "Epoch: [25][0/391]\tTime 0.621 (0.621)\tData 0.573 (0.573)\tLoss 0.9760 (0.9760)\tPrec 66.406% (66.406%)\n",
      "Epoch: [25][100/391]\tTime 0.047 (0.051)\tData 0.002 (0.007)\tLoss 0.9488 (0.9751)\tPrec 70.312% (65.617%)\n",
      "Epoch: [25][200/391]\tTime 0.048 (0.048)\tData 0.002 (0.005)\tLoss 1.1243 (0.9873)\tPrec 61.719% (65.462%)\n",
      "Epoch: [25][300/391]\tTime 0.044 (0.047)\tData 0.002 (0.004)\tLoss 0.9594 (0.9873)\tPrec 70.312% (65.508%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.251 (0.251)\tLoss 0.9997 (0.9997)\tPrec 64.062% (64.062%)\n",
      " * Prec 61.930% \n",
      "best acc: 62.360000\n",
      "Epoch: [26][0/391]\tTime 0.756 (0.756)\tData 0.709 (0.709)\tLoss 1.0469 (1.0469)\tPrec 65.625% (65.625%)\n",
      "Epoch: [26][100/391]\tTime 0.043 (0.052)\tData 0.002 (0.009)\tLoss 0.8561 (0.9734)\tPrec 70.312% (66.522%)\n",
      "Epoch: [26][200/391]\tTime 0.046 (0.049)\tData 0.002 (0.005)\tLoss 1.1809 (0.9772)\tPrec 60.938% (65.951%)\n",
      "Epoch: [26][300/391]\tTime 0.042 (0.048)\tData 0.002 (0.004)\tLoss 0.9031 (0.9781)\tPrec 70.312% (65.900%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.255 (0.255)\tLoss 0.9989 (0.9989)\tPrec 67.969% (67.969%)\n",
      " * Prec 63.490% \n",
      "best acc: 63.490000\n",
      "Epoch: [27][0/391]\tTime 0.527 (0.527)\tData 0.481 (0.481)\tLoss 0.9593 (0.9593)\tPrec 67.188% (67.188%)\n",
      "Epoch: [27][100/391]\tTime 0.049 (0.052)\tData 0.001 (0.007)\tLoss 0.9182 (0.9495)\tPrec 69.531% (66.553%)\n",
      "Epoch: [27][200/391]\tTime 0.043 (0.049)\tData 0.002 (0.004)\tLoss 0.9385 (0.9533)\tPrec 65.625% (66.445%)\n",
      "Epoch: [27][300/391]\tTime 0.045 (0.048)\tData 0.002 (0.003)\tLoss 0.7709 (0.9613)\tPrec 72.656% (66.328%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.286 (0.286)\tLoss 1.0319 (1.0319)\tPrec 63.281% (63.281%)\n",
      " * Prec 61.640% \n",
      "best acc: 63.490000\n",
      "Epoch: [28][0/391]\tTime 0.530 (0.530)\tData 0.490 (0.490)\tLoss 0.9269 (0.9269)\tPrec 67.188% (67.188%)\n",
      "Epoch: [28][100/391]\tTime 0.044 (0.049)\tData 0.001 (0.006)\tLoss 0.9419 (0.9337)\tPrec 64.844% (67.010%)\n",
      "Epoch: [28][200/391]\tTime 0.045 (0.046)\tData 0.002 (0.004)\tLoss 1.0512 (0.9450)\tPrec 62.500% (66.787%)\n",
      "Epoch: [28][300/391]\tTime 0.044 (0.045)\tData 0.001 (0.003)\tLoss 1.0885 (0.9519)\tPrec 61.719% (66.751%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.233 (0.233)\tLoss 1.0340 (1.0340)\tPrec 62.500% (62.500%)\n",
      " * Prec 63.240% \n",
      "best acc: 63.490000\n",
      "Epoch: [29][0/391]\tTime 0.840 (0.840)\tData 0.795 (0.795)\tLoss 0.8685 (0.8685)\tPrec 67.188% (67.188%)\n",
      "Epoch: [29][100/391]\tTime 0.044 (0.052)\tData 0.002 (0.009)\tLoss 0.8626 (0.9319)\tPrec 71.094% (67.466%)\n",
      "Epoch: [29][200/391]\tTime 0.043 (0.048)\tData 0.001 (0.005)\tLoss 0.9807 (0.9426)\tPrec 67.188% (67.149%)\n",
      "Epoch: [29][300/391]\tTime 0.043 (0.046)\tData 0.001 (0.004)\tLoss 0.8350 (0.9418)\tPrec 70.312% (67.156%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.366 (0.366)\tLoss 0.9882 (0.9882)\tPrec 68.750% (68.750%)\n",
      " * Prec 64.290% \n",
      "best acc: 64.290000\n",
      "Epoch: [30][0/391]\tTime 0.627 (0.627)\tData 0.576 (0.576)\tLoss 0.9416 (0.9416)\tPrec 63.281% (63.281%)\n",
      "Epoch: [30][100/391]\tTime 0.046 (0.051)\tData 0.002 (0.007)\tLoss 0.8442 (0.9102)\tPrec 73.438% (68.131%)\n",
      "Epoch: [30][200/391]\tTime 0.043 (0.048)\tData 0.002 (0.005)\tLoss 1.0799 (0.9133)\tPrec 64.062% (68.124%)\n",
      "Epoch: [30][300/391]\tTime 0.046 (0.047)\tData 0.002 (0.004)\tLoss 0.9390 (0.9247)\tPrec 64.062% (67.712%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.356 (0.356)\tLoss 1.0191 (1.0191)\tPrec 65.625% (65.625%)\n",
      " * Prec 62.830% \n",
      "best acc: 64.290000\n",
      "Epoch: [31][0/391]\tTime 0.446 (0.446)\tData 0.395 (0.395)\tLoss 0.9032 (0.9032)\tPrec 70.312% (70.312%)\n",
      "Epoch: [31][100/391]\tTime 0.048 (0.050)\tData 0.001 (0.006)\tLoss 0.8173 (0.8977)\tPrec 71.875% (68.479%)\n",
      "Epoch: [31][200/391]\tTime 0.044 (0.047)\tData 0.001 (0.004)\tLoss 1.0406 (0.9127)\tPrec 64.844% (68.175%)\n",
      "Epoch: [31][300/391]\tTime 0.042 (0.046)\tData 0.002 (0.003)\tLoss 0.8030 (0.9126)\tPrec 75.781% (68.073%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.348 (0.348)\tLoss 0.9652 (0.9652)\tPrec 64.844% (64.844%)\n",
      " * Prec 63.190% \n",
      "best acc: 64.290000\n",
      "Epoch: [32][0/391]\tTime 0.554 (0.554)\tData 0.505 (0.505)\tLoss 0.9473 (0.9473)\tPrec 64.062% (64.062%)\n",
      "Epoch: [32][100/391]\tTime 0.047 (0.050)\tData 0.002 (0.007)\tLoss 0.9386 (0.9032)\tPrec 69.531% (68.100%)\n",
      "Epoch: [32][200/391]\tTime 0.048 (0.048)\tData 0.002 (0.004)\tLoss 0.9018 (0.9037)\tPrec 69.531% (68.144%)\n",
      "Epoch: [32][300/391]\tTime 0.043 (0.047)\tData 0.002 (0.003)\tLoss 0.9581 (0.9076)\tPrec 64.844% (68.236%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.222 (0.222)\tLoss 0.9227 (0.9227)\tPrec 67.969% (67.969%)\n",
      " * Prec 64.590% \n",
      "best acc: 64.590000\n",
      "Epoch: [33][0/391]\tTime 0.474 (0.474)\tData 0.425 (0.425)\tLoss 0.8959 (0.8959)\tPrec 66.406% (66.406%)\n",
      "Epoch: [33][100/391]\tTime 0.047 (0.049)\tData 0.002 (0.006)\tLoss 0.9386 (0.8844)\tPrec 67.188% (69.067%)\n",
      "Epoch: [33][200/391]\tTime 0.043 (0.047)\tData 0.002 (0.004)\tLoss 0.8872 (0.8864)\tPrec 68.750% (69.065%)\n",
      "Epoch: [33][300/391]\tTime 0.047 (0.046)\tData 0.002 (0.003)\tLoss 1.0619 (0.8944)\tPrec 65.625% (68.753%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.348 (0.348)\tLoss 1.0164 (1.0164)\tPrec 65.625% (65.625%)\n",
      " * Prec 61.450% \n",
      "best acc: 64.590000\n",
      "Epoch: [34][0/391]\tTime 0.646 (0.646)\tData 0.596 (0.596)\tLoss 0.8901 (0.8901)\tPrec 66.406% (66.406%)\n",
      "Epoch: [34][100/391]\tTime 0.047 (0.051)\tData 0.002 (0.008)\tLoss 0.7586 (0.8730)\tPrec 75.000% (69.647%)\n",
      "Epoch: [34][200/391]\tTime 0.047 (0.048)\tData 0.002 (0.005)\tLoss 0.9451 (0.8776)\tPrec 62.500% (69.469%)\n",
      "Epoch: [34][300/391]\tTime 0.043 (0.047)\tData 0.002 (0.004)\tLoss 0.8710 (0.8831)\tPrec 72.656% (69.215%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.349 (0.349)\tLoss 0.8496 (0.8496)\tPrec 66.406% (66.406%)\n",
      " * Prec 64.630% \n",
      "best acc: 64.630000\n",
      "Epoch: [35][0/391]\tTime 0.592 (0.592)\tData 0.545 (0.545)\tLoss 0.8781 (0.8781)\tPrec 71.875% (71.875%)\n",
      "Epoch: [35][100/391]\tTime 0.044 (0.051)\tData 0.002 (0.007)\tLoss 0.9076 (0.8772)\tPrec 67.188% (69.415%)\n",
      "Epoch: [35][200/391]\tTime 0.047 (0.048)\tData 0.002 (0.004)\tLoss 0.8500 (0.8722)\tPrec 75.000% (69.679%)\n",
      "Epoch: [35][300/391]\tTime 0.046 (0.047)\tData 0.002 (0.003)\tLoss 0.7602 (0.8767)\tPrec 71.875% (69.451%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.351 (0.351)\tLoss 0.9964 (0.9964)\tPrec 68.750% (68.750%)\n",
      " * Prec 63.520% \n",
      "best acc: 64.630000\n",
      "Epoch: [36][0/391]\tTime 0.645 (0.645)\tData 0.594 (0.594)\tLoss 0.9224 (0.9224)\tPrec 74.219% (74.219%)\n",
      "Epoch: [36][100/391]\tTime 0.044 (0.051)\tData 0.002 (0.008)\tLoss 0.8939 (0.8647)\tPrec 63.281% (69.887%)\n",
      "Epoch: [36][200/391]\tTime 0.043 (0.048)\tData 0.002 (0.005)\tLoss 1.0168 (0.8612)\tPrec 67.188% (69.803%)\n",
      "Epoch: [36][300/391]\tTime 0.047 (0.047)\tData 0.002 (0.004)\tLoss 0.9147 (0.8672)\tPrec 64.844% (69.549%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.552 (0.552)\tLoss 0.9284 (0.9284)\tPrec 66.406% (66.406%)\n",
      " * Prec 62.620% \n",
      "best acc: 64.630000\n",
      "Epoch: [37][0/391]\tTime 0.762 (0.762)\tData 0.711 (0.711)\tLoss 0.7433 (0.7433)\tPrec 74.219% (74.219%)\n",
      "Epoch: [37][100/391]\tTime 0.046 (0.052)\tData 0.002 (0.009)\tLoss 0.7350 (0.8598)\tPrec 78.125% (70.011%)\n",
      "Epoch: [37][200/391]\tTime 0.045 (0.049)\tData 0.002 (0.005)\tLoss 0.7827 (0.8540)\tPrec 71.094% (70.052%)\n",
      "Epoch: [37][300/391]\tTime 0.044 (0.048)\tData 0.002 (0.004)\tLoss 0.9796 (0.8578)\tPrec 64.062% (70.139%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.317 (0.317)\tLoss 0.9035 (0.9035)\tPrec 64.844% (64.844%)\n",
      " * Prec 64.650% \n",
      "best acc: 64.650000\n",
      "Epoch: [38][0/391]\tTime 0.632 (0.632)\tData 0.580 (0.580)\tLoss 0.8757 (0.8757)\tPrec 74.219% (74.219%)\n",
      "Epoch: [38][100/391]\tTime 0.046 (0.051)\tData 0.002 (0.008)\tLoss 0.8359 (0.8479)\tPrec 74.219% (70.436%)\n",
      "Epoch: [38][200/391]\tTime 0.044 (0.048)\tData 0.002 (0.005)\tLoss 0.9364 (0.8475)\tPrec 63.281% (70.425%)\n",
      "Epoch: [38][300/391]\tTime 0.047 (0.047)\tData 0.002 (0.004)\tLoss 0.9222 (0.8511)\tPrec 65.625% (70.266%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.461 (0.461)\tLoss 0.9233 (0.9233)\tPrec 62.500% (62.500%)\n",
      " * Prec 64.400% \n",
      "best acc: 64.650000\n",
      "Epoch: [39][0/391]\tTime 0.635 (0.635)\tData 0.586 (0.586)\tLoss 0.7402 (0.7402)\tPrec 75.781% (75.781%)\n",
      "Epoch: [39][100/391]\tTime 0.043 (0.051)\tData 0.002 (0.008)\tLoss 0.8471 (0.8282)\tPrec 67.969% (71.179%)\n",
      "Epoch: [39][200/391]\tTime 0.047 (0.048)\tData 0.002 (0.005)\tLoss 0.7556 (0.8315)\tPrec 75.000% (70.911%)\n",
      "Epoch: [39][300/391]\tTime 0.045 (0.047)\tData 0.002 (0.004)\tLoss 0.9323 (0.8371)\tPrec 67.188% (70.598%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.449 (0.449)\tLoss 0.9347 (0.9347)\tPrec 67.188% (67.188%)\n",
      " * Prec 63.680% \n",
      "best acc: 64.650000\n",
      "Epoch: [40][0/391]\tTime 0.642 (0.642)\tData 0.603 (0.603)\tLoss 0.7649 (0.7649)\tPrec 75.781% (75.781%)\n",
      "Epoch: [40][100/391]\tTime 0.045 (0.051)\tData 0.002 (0.008)\tLoss 0.7598 (0.8331)\tPrec 77.344% (70.413%)\n",
      "Epoch: [40][200/391]\tTime 0.047 (0.048)\tData 0.002 (0.005)\tLoss 0.8869 (0.8322)\tPrec 67.969% (70.456%)\n",
      "Epoch: [40][300/391]\tTime 0.047 (0.047)\tData 0.002 (0.004)\tLoss 0.6818 (0.8304)\tPrec 74.219% (70.673%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.354 (0.354)\tLoss 0.9504 (0.9504)\tPrec 66.406% (66.406%)\n",
      " * Prec 63.710% \n",
      "best acc: 64.650000\n",
      "Epoch: [41][0/391]\tTime 0.628 (0.628)\tData 0.577 (0.577)\tLoss 0.8052 (0.8052)\tPrec 75.000% (75.000%)\n",
      "Epoch: [41][100/391]\tTime 0.043 (0.051)\tData 0.002 (0.007)\tLoss 0.7710 (0.8060)\tPrec 75.781% (71.952%)\n",
      "Epoch: [41][200/391]\tTime 0.045 (0.048)\tData 0.002 (0.005)\tLoss 0.7460 (0.8197)\tPrec 71.094% (71.385%)\n",
      "Epoch: [41][300/391]\tTime 0.047 (0.047)\tData 0.002 (0.004)\tLoss 0.9018 (0.8210)\tPrec 69.531% (71.400%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.356 (0.356)\tLoss 0.8305 (0.8305)\tPrec 68.750% (68.750%)\n",
      " * Prec 64.490% \n",
      "best acc: 64.650000\n",
      "Epoch: [42][0/391]\tTime 0.765 (0.765)\tData 0.716 (0.716)\tLoss 0.7967 (0.7967)\tPrec 75.781% (75.781%)\n",
      "Epoch: [42][100/391]\tTime 0.045 (0.052)\tData 0.002 (0.009)\tLoss 0.8218 (0.8010)\tPrec 72.656% (72.092%)\n",
      "Epoch: [42][200/391]\tTime 0.047 (0.049)\tData 0.002 (0.005)\tLoss 0.8019 (0.8209)\tPrec 75.781% (71.257%)\n",
      "Epoch: [42][300/391]\tTime 0.047 (0.047)\tData 0.002 (0.004)\tLoss 0.8118 (0.8231)\tPrec 70.312% (71.187%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.362 (0.362)\tLoss 0.9605 (0.9605)\tPrec 67.188% (67.188%)\n",
      " * Prec 65.310% \n",
      "best acc: 65.310000\n",
      "Epoch: [43][0/391]\tTime 1.194 (1.194)\tData 1.144 (1.144)\tLoss 0.8737 (0.8737)\tPrec 69.531% (69.531%)\n",
      "Epoch: [43][100/391]\tTime 0.047 (0.056)\tData 0.002 (0.013)\tLoss 0.7803 (0.8039)\tPrec 74.219% (71.697%)\n",
      "Epoch: [43][200/391]\tTime 0.045 (0.051)\tData 0.002 (0.007)\tLoss 0.8781 (0.8048)\tPrec 70.312% (71.622%)\n",
      "Epoch: [43][300/391]\tTime 0.045 (0.049)\tData 0.002 (0.006)\tLoss 0.7386 (0.8090)\tPrec 73.438% (71.548%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.238 (0.238)\tLoss 0.8944 (0.8944)\tPrec 69.531% (69.531%)\n",
      " * Prec 64.930% \n",
      "best acc: 65.310000\n",
      "Epoch: [44][0/391]\tTime 0.735 (0.735)\tData 0.685 (0.685)\tLoss 0.7497 (0.7497)\tPrec 71.094% (71.094%)\n",
      "Epoch: [44][100/391]\tTime 0.048 (0.052)\tData 0.002 (0.009)\tLoss 0.8683 (0.8004)\tPrec 70.312% (72.022%)\n",
      "Epoch: [44][200/391]\tTime 0.043 (0.049)\tData 0.002 (0.005)\tLoss 0.7820 (0.8002)\tPrec 71.875% (72.003%)\n",
      "Epoch: [44][300/391]\tTime 0.044 (0.048)\tData 0.002 (0.004)\tLoss 0.9238 (0.8017)\tPrec 68.750% (71.802%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.255 (0.255)\tLoss 0.9999 (0.9999)\tPrec 66.406% (66.406%)\n",
      " * Prec 64.650% \n",
      "best acc: 65.310000\n",
      "Epoch: [45][0/391]\tTime 0.830 (0.830)\tData 0.779 (0.779)\tLoss 0.9197 (0.9197)\tPrec 68.750% (68.750%)\n",
      "Epoch: [45][100/391]\tTime 0.047 (0.053)\tData 0.002 (0.010)\tLoss 0.8835 (0.7786)\tPrec 67.969% (72.532%)\n",
      "Epoch: [45][200/391]\tTime 0.047 (0.049)\tData 0.002 (0.006)\tLoss 0.6887 (0.7957)\tPrec 75.781% (71.828%)\n",
      "Epoch: [45][300/391]\tTime 0.043 (0.048)\tData 0.002 (0.004)\tLoss 0.7367 (0.7955)\tPrec 72.656% (71.963%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.357 (0.357)\tLoss 0.9850 (0.9850)\tPrec 66.406% (66.406%)\n",
      " * Prec 64.630% \n",
      "best acc: 65.310000\n",
      "Epoch: [46][0/391]\tTime 0.844 (0.844)\tData 0.795 (0.795)\tLoss 0.7244 (0.7244)\tPrec 71.875% (71.875%)\n",
      "Epoch: [46][100/391]\tTime 0.044 (0.053)\tData 0.002 (0.010)\tLoss 0.8780 (0.7891)\tPrec 74.219% (72.718%)\n",
      "Epoch: [46][200/391]\tTime 0.043 (0.049)\tData 0.002 (0.006)\tLoss 0.7643 (0.7755)\tPrec 72.656% (72.831%)\n",
      "Epoch: [46][300/391]\tTime 0.047 (0.048)\tData 0.002 (0.004)\tLoss 0.7199 (0.7817)\tPrec 73.438% (72.677%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.236 (0.236)\tLoss 0.9768 (0.9768)\tPrec 71.094% (71.094%)\n",
      " * Prec 66.210% \n",
      "best acc: 66.210000\n",
      "Epoch: [47][0/391]\tTime 0.624 (0.624)\tData 0.584 (0.584)\tLoss 0.8076 (0.8076)\tPrec 72.656% (72.656%)\n",
      "Epoch: [47][100/391]\tTime 0.050 (0.051)\tData 0.002 (0.008)\tLoss 1.0186 (0.7607)\tPrec 67.188% (73.360%)\n",
      "Epoch: [47][200/391]\tTime 0.045 (0.048)\tData 0.002 (0.005)\tLoss 0.8993 (0.7658)\tPrec 67.969% (73.006%)\n",
      "Epoch: [47][300/391]\tTime 0.047 (0.047)\tData 0.001 (0.004)\tLoss 0.7732 (0.7768)\tPrec 69.531% (72.708%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.453 (0.453)\tLoss 0.9136 (0.9136)\tPrec 72.656% (72.656%)\n",
      " * Prec 66.210% \n",
      "best acc: 66.210000\n",
      "Epoch: [48][0/391]\tTime 0.841 (0.841)\tData 0.791 (0.791)\tLoss 0.6774 (0.6774)\tPrec 74.219% (74.219%)\n",
      "Epoch: [48][100/391]\tTime 0.047 (0.053)\tData 0.002 (0.010)\tLoss 0.9082 (0.7729)\tPrec 67.969% (73.182%)\n",
      "Epoch: [48][200/391]\tTime 0.048 (0.049)\tData 0.002 (0.006)\tLoss 0.8617 (0.7646)\tPrec 65.625% (73.228%)\n",
      "Epoch: [48][300/391]\tTime 0.046 (0.048)\tData 0.002 (0.004)\tLoss 0.8212 (0.7738)\tPrec 69.531% (72.864%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.353 (0.353)\tLoss 0.9221 (0.9221)\tPrec 70.312% (70.312%)\n",
      " * Prec 65.540% \n",
      "best acc: 66.210000\n",
      "Epoch: [49][0/391]\tTime 0.543 (0.543)\tData 0.494 (0.494)\tLoss 0.7371 (0.7371)\tPrec 77.344% (77.344%)\n",
      "Epoch: [49][100/391]\tTime 0.043 (0.050)\tData 0.002 (0.007)\tLoss 0.7716 (0.7590)\tPrec 70.312% (73.213%)\n",
      "Epoch: [49][200/391]\tTime 0.043 (0.048)\tData 0.002 (0.004)\tLoss 0.8242 (0.7616)\tPrec 71.094% (73.134%)\n",
      "Epoch: [49][300/391]\tTime 0.044 (0.047)\tData 0.002 (0.003)\tLoss 0.8540 (0.7618)\tPrec 68.750% (73.142%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.336 (0.336)\tLoss 0.8565 (0.8565)\tPrec 69.531% (69.531%)\n",
      " * Prec 65.990% \n",
      "best acc: 66.210000\n",
      "Epoch: [50][0/391]\tTime 0.654 (0.654)\tData 0.608 (0.608)\tLoss 0.7362 (0.7362)\tPrec 77.344% (77.344%)\n",
      "Epoch: [50][100/391]\tTime 0.047 (0.051)\tData 0.002 (0.008)\tLoss 0.8357 (0.7289)\tPrec 71.094% (74.265%)\n",
      "Epoch: [50][200/391]\tTime 0.044 (0.048)\tData 0.002 (0.005)\tLoss 0.5913 (0.7359)\tPrec 78.125% (74.071%)\n",
      "Epoch: [50][300/391]\tTime 0.043 (0.047)\tData 0.002 (0.004)\tLoss 0.6537 (0.7451)\tPrec 75.000% (73.681%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.439 (0.439)\tLoss 0.9964 (0.9964)\tPrec 70.312% (70.312%)\n",
      " * Prec 65.110% \n",
      "best acc: 66.210000\n",
      "Epoch: [51][0/391]\tTime 0.566 (0.566)\tData 0.516 (0.516)\tLoss 0.6726 (0.6726)\tPrec 78.906% (78.906%)\n",
      "Epoch: [51][100/391]\tTime 0.045 (0.051)\tData 0.002 (0.007)\tLoss 0.6948 (0.7561)\tPrec 75.000% (73.236%)\n",
      "Epoch: [51][200/391]\tTime 0.047 (0.048)\tData 0.002 (0.004)\tLoss 0.7350 (0.7466)\tPrec 76.562% (73.702%)\n",
      "Epoch: [51][300/391]\tTime 0.046 (0.047)\tData 0.002 (0.003)\tLoss 0.8008 (0.7483)\tPrec 71.875% (73.663%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.249 (0.249)\tLoss 1.0525 (1.0525)\tPrec 67.969% (67.969%)\n",
      " * Prec 65.600% \n",
      "best acc: 66.210000\n",
      "Epoch: [52][0/391]\tTime 0.770 (0.770)\tData 0.720 (0.720)\tLoss 0.9622 (0.9622)\tPrec 63.281% (63.281%)\n",
      "Epoch: [52][100/391]\tTime 0.047 (0.052)\tData 0.002 (0.009)\tLoss 0.7117 (0.7413)\tPrec 74.219% (74.157%)\n",
      "Epoch: [52][200/391]\tTime 0.047 (0.049)\tData 0.002 (0.005)\tLoss 0.7447 (0.7451)\tPrec 76.562% (73.791%)\n",
      "Epoch: [52][300/391]\tTime 0.043 (0.047)\tData 0.002 (0.004)\tLoss 0.7736 (0.7411)\tPrec 74.219% (74.084%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.254 (0.254)\tLoss 0.8557 (0.8557)\tPrec 70.312% (70.312%)\n",
      " * Prec 65.770% \n",
      "best acc: 66.210000\n",
      "Epoch: [53][0/391]\tTime 0.529 (0.529)\tData 0.488 (0.488)\tLoss 0.5949 (0.5949)\tPrec 77.344% (77.344%)\n",
      "Epoch: [53][100/391]\tTime 0.043 (0.050)\tData 0.002 (0.007)\tLoss 0.7041 (0.7209)\tPrec 73.438% (74.752%)\n",
      "Epoch: [53][200/391]\tTime 0.045 (0.047)\tData 0.002 (0.004)\tLoss 0.6972 (0.7278)\tPrec 77.344% (74.382%)\n",
      "Epoch: [53][300/391]\tTime 0.045 (0.047)\tData 0.002 (0.003)\tLoss 0.7214 (0.7303)\tPrec 71.875% (74.323%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.262 (0.262)\tLoss 0.9131 (0.9131)\tPrec 70.312% (70.312%)\n",
      " * Prec 66.520% \n",
      "best acc: 66.520000\n",
      "Epoch: [54][0/391]\tTime 0.691 (0.691)\tData 0.640 (0.640)\tLoss 0.7162 (0.7162)\tPrec 75.000% (75.000%)\n",
      "Epoch: [54][100/391]\tTime 0.046 (0.051)\tData 0.002 (0.008)\tLoss 0.6874 (0.7145)\tPrec 75.000% (75.101%)\n",
      "Epoch: [54][200/391]\tTime 0.045 (0.048)\tData 0.002 (0.005)\tLoss 0.6905 (0.7209)\tPrec 73.438% (74.720%)\n",
      "Epoch: [54][300/391]\tTime 0.043 (0.047)\tData 0.002 (0.004)\tLoss 0.8333 (0.7304)\tPrec 70.312% (74.245%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.298 (0.298)\tLoss 0.8980 (0.8980)\tPrec 69.531% (69.531%)\n",
      " * Prec 65.440% \n",
      "best acc: 66.520000\n",
      "Epoch: [55][0/391]\tTime 0.679 (0.679)\tData 0.624 (0.624)\tLoss 0.7452 (0.7452)\tPrec 71.094% (71.094%)\n",
      "Epoch: [55][100/391]\tTime 0.049 (0.052)\tData 0.002 (0.008)\tLoss 0.6614 (0.7116)\tPrec 78.125% (74.869%)\n",
      "Epoch: [55][200/391]\tTime 0.043 (0.048)\tData 0.002 (0.005)\tLoss 0.8590 (0.7151)\tPrec 67.969% (74.743%)\n",
      "Epoch: [55][300/391]\tTime 0.045 (0.047)\tData 0.002 (0.004)\tLoss 0.8103 (0.7205)\tPrec 73.438% (74.660%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.542 (0.542)\tLoss 0.9037 (0.9037)\tPrec 72.656% (72.656%)\n",
      " * Prec 66.490% \n",
      "best acc: 66.520000\n",
      "Epoch: [56][0/391]\tTime 0.615 (0.615)\tData 0.570 (0.570)\tLoss 0.6547 (0.6547)\tPrec 76.562% (76.562%)\n",
      "Epoch: [56][100/391]\tTime 0.045 (0.050)\tData 0.002 (0.007)\tLoss 0.5940 (0.7068)\tPrec 78.125% (74.923%)\n",
      "Epoch: [56][200/391]\tTime 0.042 (0.047)\tData 0.002 (0.005)\tLoss 0.6558 (0.7140)\tPrec 77.344% (74.708%)\n",
      "Epoch: [56][300/391]\tTime 0.049 (0.046)\tData 0.002 (0.004)\tLoss 0.7525 (0.7171)\tPrec 75.781% (74.616%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.425 (0.425)\tLoss 0.9259 (0.9259)\tPrec 70.312% (70.312%)\n",
      " * Prec 66.740% \n",
      "best acc: 66.740000\n",
      "Epoch: [57][0/391]\tTime 0.580 (0.580)\tData 0.533 (0.533)\tLoss 0.7309 (0.7309)\tPrec 70.312% (70.312%)\n",
      "Epoch: [57][100/391]\tTime 0.043 (0.051)\tData 0.002 (0.007)\tLoss 0.7568 (0.7126)\tPrec 74.219% (75.356%)\n",
      "Epoch: [57][200/391]\tTime 0.040 (0.047)\tData 0.002 (0.004)\tLoss 0.7142 (0.7081)\tPrec 75.000% (75.175%)\n",
      "Epoch: [57][300/391]\tTime 0.045 (0.047)\tData 0.002 (0.003)\tLoss 0.7202 (0.7117)\tPrec 78.906% (75.000%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.232 (0.232)\tLoss 0.9940 (0.9940)\tPrec 68.750% (68.750%)\n",
      " * Prec 65.560% \n",
      "best acc: 66.740000\n",
      "Epoch: [58][0/391]\tTime 0.553 (0.553)\tData 0.507 (0.507)\tLoss 0.6571 (0.6571)\tPrec 77.344% (77.344%)\n",
      "Epoch: [58][100/391]\tTime 0.044 (0.049)\tData 0.002 (0.007)\tLoss 0.7619 (0.6972)\tPrec 74.219% (75.433%)\n",
      "Epoch: [58][200/391]\tTime 0.044 (0.047)\tData 0.002 (0.004)\tLoss 0.8117 (0.6974)\tPrec 71.875% (75.420%)\n",
      "Epoch: [58][300/391]\tTime 0.045 (0.046)\tData 0.002 (0.003)\tLoss 0.7198 (0.7039)\tPrec 80.469% (75.231%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.226 (0.226)\tLoss 0.8748 (0.8748)\tPrec 69.531% (69.531%)\n",
      " * Prec 65.250% \n",
      "best acc: 66.740000\n",
      "Epoch: [59][0/391]\tTime 0.781 (0.781)\tData 0.730 (0.730)\tLoss 0.6014 (0.6014)\tPrec 76.562% (76.562%)\n",
      "Epoch: [59][100/391]\tTime 0.043 (0.053)\tData 0.002 (0.009)\tLoss 0.6213 (0.6799)\tPrec 77.344% (75.851%)\n",
      "Epoch: [59][200/391]\tTime 0.046 (0.049)\tData 0.002 (0.005)\tLoss 0.6093 (0.6902)\tPrec 81.250% (75.781%)\n",
      "Epoch: [59][300/391]\tTime 0.046 (0.048)\tData 0.002 (0.004)\tLoss 0.5913 (0.6988)\tPrec 82.812% (75.485%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.261 (0.261)\tLoss 0.9640 (0.9640)\tPrec 67.969% (67.969%)\n",
      " * Prec 64.680% \n",
      "best acc: 66.740000\n",
      "Epoch: [60][0/391]\tTime 0.719 (0.719)\tData 0.670 (0.670)\tLoss 0.6063 (0.6063)\tPrec 77.344% (77.344%)\n",
      "Epoch: [60][100/391]\tTime 0.047 (0.052)\tData 0.002 (0.008)\tLoss 0.8171 (0.6794)\tPrec 68.750% (76.006%)\n",
      "Epoch: [60][200/391]\tTime 0.044 (0.048)\tData 0.002 (0.005)\tLoss 0.6940 (0.6838)\tPrec 77.344% (75.855%)\n",
      "Epoch: [60][300/391]\tTime 0.048 (0.047)\tData 0.002 (0.004)\tLoss 0.5687 (0.6892)\tPrec 81.250% (75.548%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.548 (0.548)\tLoss 0.9080 (0.9080)\tPrec 67.188% (67.188%)\n",
      " * Prec 66.050% \n",
      "best acc: 66.740000\n",
      "Epoch: [61][0/391]\tTime 0.844 (0.844)\tData 0.796 (0.796)\tLoss 0.7313 (0.7313)\tPrec 75.781% (75.781%)\n",
      "Epoch: [61][100/391]\tTime 0.043 (0.053)\tData 0.002 (0.010)\tLoss 0.6671 (0.6749)\tPrec 78.906% (76.632%)\n",
      "Epoch: [61][200/391]\tTime 0.044 (0.049)\tData 0.002 (0.006)\tLoss 0.5436 (0.6821)\tPrec 81.250% (76.150%)\n",
      "Epoch: [61][300/391]\tTime 0.043 (0.048)\tData 0.002 (0.004)\tLoss 0.6951 (0.6899)\tPrec 75.781% (75.701%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.291 (0.291)\tLoss 1.0689 (1.0689)\tPrec 64.062% (64.062%)\n",
      " * Prec 64.520% \n",
      "best acc: 66.740000\n",
      "Epoch: [62][0/391]\tTime 0.681 (0.681)\tData 0.629 (0.629)\tLoss 0.6602 (0.6602)\tPrec 78.906% (78.906%)\n",
      "Epoch: [62][100/391]\tTime 0.047 (0.052)\tData 0.002 (0.008)\tLoss 0.6320 (0.6603)\tPrec 78.906% (76.942%)\n",
      "Epoch: [62][200/391]\tTime 0.046 (0.049)\tData 0.002 (0.005)\tLoss 0.7237 (0.6771)\tPrec 74.219% (76.150%)\n",
      "Epoch: [62][300/391]\tTime 0.046 (0.048)\tData 0.002 (0.004)\tLoss 0.8785 (0.6838)\tPrec 68.750% (75.880%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.231 (0.231)\tLoss 0.7923 (0.7923)\tPrec 71.875% (71.875%)\n",
      " * Prec 66.600% \n",
      "best acc: 66.740000\n",
      "Epoch: [63][0/391]\tTime 0.654 (0.654)\tData 0.604 (0.604)\tLoss 0.6199 (0.6199)\tPrec 78.906% (78.906%)\n",
      "Epoch: [63][100/391]\tTime 0.047 (0.051)\tData 0.002 (0.008)\tLoss 0.7300 (0.6584)\tPrec 73.438% (76.996%)\n",
      "Epoch: [63][200/391]\tTime 0.044 (0.048)\tData 0.002 (0.005)\tLoss 0.7851 (0.6729)\tPrec 72.656% (76.275%)\n",
      "Epoch: [63][300/391]\tTime 0.047 (0.047)\tData 0.002 (0.004)\tLoss 0.8760 (0.6720)\tPrec 65.625% (76.308%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.352 (0.352)\tLoss 0.9013 (0.9013)\tPrec 71.094% (71.094%)\n",
      " * Prec 66.410% \n",
      "best acc: 66.740000\n",
      "Epoch: [64][0/391]\tTime 0.584 (0.584)\tData 0.538 (0.538)\tLoss 0.6543 (0.6543)\tPrec 75.781% (75.781%)\n",
      "Epoch: [64][100/391]\tTime 0.043 (0.050)\tData 0.002 (0.007)\tLoss 0.7073 (0.6417)\tPrec 74.219% (77.189%)\n",
      "Epoch: [64][200/391]\tTime 0.047 (0.048)\tData 0.002 (0.004)\tLoss 0.7176 (0.6586)\tPrec 74.219% (76.660%)\n",
      "Epoch: [64][300/391]\tTime 0.047 (0.047)\tData 0.002 (0.004)\tLoss 0.5387 (0.6648)\tPrec 82.812% (76.451%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.239 (0.239)\tLoss 1.0609 (1.0609)\tPrec 71.875% (71.875%)\n",
      " * Prec 65.540% \n",
      "best acc: 66.740000\n",
      "Epoch: [65][0/391]\tTime 0.746 (0.746)\tData 0.701 (0.701)\tLoss 0.7080 (0.7080)\tPrec 76.562% (76.562%)\n",
      "Epoch: [65][100/391]\tTime 0.041 (0.051)\tData 0.001 (0.009)\tLoss 0.6327 (0.6576)\tPrec 77.344% (76.841%)\n",
      "Epoch: [65][200/391]\tTime 0.044 (0.047)\tData 0.002 (0.005)\tLoss 0.6213 (0.6640)\tPrec 78.125% (76.757%)\n",
      "Epoch: [65][300/391]\tTime 0.043 (0.047)\tData 0.002 (0.004)\tLoss 0.6781 (0.6669)\tPrec 73.438% (76.575%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.353 (0.353)\tLoss 1.0144 (1.0144)\tPrec 71.094% (71.094%)\n",
      " * Prec 66.230% \n",
      "best acc: 66.740000\n",
      "Epoch: [66][0/391]\tTime 0.480 (0.480)\tData 0.436 (0.436)\tLoss 0.5985 (0.5985)\tPrec 79.688% (79.688%)\n",
      "Epoch: [66][100/391]\tTime 0.048 (0.050)\tData 0.002 (0.006)\tLoss 0.4826 (0.6413)\tPrec 81.250% (77.560%)\n",
      "Epoch: [66][200/391]\tTime 0.048 (0.048)\tData 0.002 (0.004)\tLoss 0.4752 (0.6505)\tPrec 83.594% (77.111%)\n",
      "Epoch: [66][300/391]\tTime 0.044 (0.047)\tData 0.002 (0.003)\tLoss 0.7369 (0.6600)\tPrec 73.438% (76.687%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.341 (0.341)\tLoss 0.9216 (0.9216)\tPrec 66.406% (66.406%)\n",
      " * Prec 66.310% \n",
      "best acc: 66.740000\n",
      "Epoch: [67][0/391]\tTime 0.751 (0.751)\tData 0.700 (0.700)\tLoss 0.5752 (0.5752)\tPrec 82.031% (82.031%)\n",
      "Epoch: [67][100/391]\tTime 0.048 (0.052)\tData 0.002 (0.009)\tLoss 0.7265 (0.6457)\tPrec 73.438% (77.073%)\n",
      "Epoch: [67][200/391]\tTime 0.045 (0.049)\tData 0.002 (0.005)\tLoss 0.6471 (0.6560)\tPrec 79.688% (76.850%)\n",
      "Epoch: [67][300/391]\tTime 0.045 (0.048)\tData 0.002 (0.004)\tLoss 0.5268 (0.6540)\tPrec 78.906% (76.827%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.347 (0.347)\tLoss 1.0655 (1.0655)\tPrec 65.625% (65.625%)\n",
      " * Prec 66.020% \n",
      "best acc: 66.740000\n",
      "Epoch: [68][0/391]\tTime 0.574 (0.574)\tData 0.526 (0.526)\tLoss 0.7879 (0.7879)\tPrec 71.875% (71.875%)\n",
      "Epoch: [68][100/391]\tTime 0.045 (0.051)\tData 0.002 (0.007)\tLoss 0.5993 (0.6281)\tPrec 78.906% (77.761%)\n",
      "Epoch: [68][200/391]\tTime 0.046 (0.048)\tData 0.002 (0.004)\tLoss 0.6901 (0.6345)\tPrec 73.438% (77.355%)\n",
      "Epoch: [68][300/391]\tTime 0.047 (0.047)\tData 0.002 (0.004)\tLoss 0.6881 (0.6430)\tPrec 77.344% (77.237%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.257 (0.257)\tLoss 1.0524 (1.0524)\tPrec 61.719% (61.719%)\n",
      " * Prec 65.550% \n",
      "best acc: 66.740000\n",
      "Epoch: [69][0/391]\tTime 0.673 (0.673)\tData 0.622 (0.622)\tLoss 0.6922 (0.6922)\tPrec 77.344% (77.344%)\n",
      "Epoch: [69][100/391]\tTime 0.045 (0.051)\tData 0.002 (0.008)\tLoss 0.6323 (0.6369)\tPrec 72.656% (77.684%)\n",
      "Epoch: [69][200/391]\tTime 0.045 (0.048)\tData 0.002 (0.005)\tLoss 0.6367 (0.6407)\tPrec 77.344% (77.682%)\n",
      "Epoch: [69][300/391]\tTime 0.047 (0.047)\tData 0.002 (0.004)\tLoss 0.6713 (0.6475)\tPrec 75.000% (77.393%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.354 (0.354)\tLoss 1.0057 (1.0057)\tPrec 71.875% (71.875%)\n",
      " * Prec 65.860% \n",
      "best acc: 66.740000\n",
      "Epoch: [70][0/391]\tTime 1.141 (1.141)\tData 1.091 (1.091)\tLoss 0.4812 (0.4812)\tPrec 85.156% (85.156%)\n",
      "Epoch: [70][100/391]\tTime 0.047 (0.056)\tData 0.002 (0.013)\tLoss 0.5448 (0.6364)\tPrec 77.344% (77.498%)\n",
      "Epoch: [70][200/391]\tTime 0.046 (0.051)\tData 0.002 (0.007)\tLoss 0.7042 (0.6397)\tPrec 75.781% (77.526%)\n",
      "Epoch: [70][300/391]\tTime 0.048 (0.049)\tData 0.001 (0.005)\tLoss 0.6171 (0.6400)\tPrec 75.781% (77.611%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.235 (0.235)\tLoss 0.9219 (0.9219)\tPrec 67.969% (67.969%)\n",
      " * Prec 66.980% \n",
      "best acc: 66.980000\n",
      "Epoch: [71][0/391]\tTime 0.614 (0.614)\tData 0.565 (0.565)\tLoss 0.5691 (0.5691)\tPrec 78.906% (78.906%)\n",
      "Epoch: [71][100/391]\tTime 0.043 (0.051)\tData 0.002 (0.007)\tLoss 0.7578 (0.6279)\tPrec 73.438% (77.754%)\n",
      "Epoch: [71][200/391]\tTime 0.043 (0.048)\tData 0.002 (0.005)\tLoss 0.6701 (0.6339)\tPrec 73.438% (77.394%)\n",
      "Epoch: [71][300/391]\tTime 0.047 (0.047)\tData 0.002 (0.004)\tLoss 0.5420 (0.6361)\tPrec 81.250% (77.461%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.346 (0.346)\tLoss 0.8617 (0.8617)\tPrec 69.531% (69.531%)\n",
      " * Prec 65.940% \n",
      "best acc: 66.980000\n",
      "Epoch: [72][0/391]\tTime 0.832 (0.832)\tData 0.781 (0.781)\tLoss 0.7434 (0.7434)\tPrec 71.875% (71.875%)\n",
      "Epoch: [72][100/391]\tTime 0.043 (0.053)\tData 0.002 (0.010)\tLoss 0.7407 (0.6098)\tPrec 74.219% (78.434%)\n",
      "Epoch: [72][200/391]\tTime 0.045 (0.049)\tData 0.002 (0.006)\tLoss 0.4897 (0.6141)\tPrec 84.375% (78.288%)\n",
      "Epoch: [72][300/391]\tTime 0.043 (0.048)\tData 0.002 (0.004)\tLoss 0.6396 (0.6233)\tPrec 80.469% (78.042%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.419 (0.419)\tLoss 0.9096 (0.9096)\tPrec 72.656% (72.656%)\n",
      " * Prec 66.120% \n",
      "best acc: 66.980000\n",
      "Epoch: [73][0/391]\tTime 0.632 (0.632)\tData 0.586 (0.586)\tLoss 0.6158 (0.6158)\tPrec 83.594% (83.594%)\n",
      "Epoch: [73][100/391]\tTime 0.042 (0.051)\tData 0.002 (0.008)\tLoss 0.5559 (0.6190)\tPrec 84.375% (78.287%)\n",
      "Epoch: [73][200/391]\tTime 0.047 (0.048)\tData 0.001 (0.005)\tLoss 0.4776 (0.6258)\tPrec 83.594% (77.872%)\n",
      "Epoch: [73][300/391]\tTime 0.046 (0.047)\tData 0.001 (0.004)\tLoss 0.4833 (0.6268)\tPrec 83.594% (77.876%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.248 (0.248)\tLoss 0.9975 (0.9975)\tPrec 68.750% (68.750%)\n",
      " * Prec 66.660% \n",
      "best acc: 66.980000\n",
      "Epoch: [74][0/391]\tTime 0.546 (0.546)\tData 0.500 (0.500)\tLoss 0.5062 (0.5062)\tPrec 82.031% (82.031%)\n",
      "Epoch: [74][100/391]\tTime 0.048 (0.050)\tData 0.002 (0.007)\tLoss 0.6653 (0.6042)\tPrec 76.562% (78.643%)\n",
      "Epoch: [74][200/391]\tTime 0.045 (0.048)\tData 0.002 (0.004)\tLoss 0.5535 (0.6082)\tPrec 80.469% (78.545%)\n",
      "Epoch: [74][300/391]\tTime 0.044 (0.047)\tData 0.002 (0.003)\tLoss 0.6818 (0.6135)\tPrec 77.344% (78.255%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.254 (0.254)\tLoss 0.9736 (0.9736)\tPrec 67.969% (67.969%)\n",
      " * Prec 65.970% \n",
      "best acc: 66.980000\n",
      "Epoch: [75][0/391]\tTime 0.908 (0.908)\tData 0.863 (0.863)\tLoss 0.5819 (0.5819)\tPrec 79.688% (79.688%)\n",
      "Epoch: [75][100/391]\tTime 0.044 (0.054)\tData 0.002 (0.010)\tLoss 0.4934 (0.5860)\tPrec 80.469% (79.270%)\n",
      "Epoch: [75][200/391]\tTime 0.045 (0.049)\tData 0.002 (0.006)\tLoss 0.5955 (0.6125)\tPrec 77.344% (78.207%)\n",
      "Epoch: [75][300/391]\tTime 0.044 (0.048)\tData 0.002 (0.005)\tLoss 0.6440 (0.6147)\tPrec 71.875% (78.167%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.254 (0.254)\tLoss 0.9545 (0.9545)\tPrec 70.312% (70.312%)\n",
      " * Prec 66.810% \n",
      "best acc: 66.980000\n",
      "Epoch: [76][0/391]\tTime 0.510 (0.510)\tData 0.463 (0.463)\tLoss 0.5462 (0.5462)\tPrec 81.250% (81.250%)\n",
      "Epoch: [76][100/391]\tTime 0.042 (0.050)\tData 0.002 (0.006)\tLoss 0.5784 (0.5949)\tPrec 80.469% (78.899%)\n",
      "Epoch: [76][200/391]\tTime 0.047 (0.047)\tData 0.002 (0.004)\tLoss 0.6183 (0.6009)\tPrec 75.000% (78.634%)\n",
      "Epoch: [76][300/391]\tTime 0.043 (0.046)\tData 0.002 (0.003)\tLoss 0.6793 (0.6122)\tPrec 77.344% (78.317%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.329 (0.329)\tLoss 1.0198 (1.0198)\tPrec 67.969% (67.969%)\n",
      " * Prec 66.740% \n",
      "best acc: 66.980000\n",
      "Epoch: [77][0/391]\tTime 0.856 (0.856)\tData 0.806 (0.806)\tLoss 0.6958 (0.6958)\tPrec 78.125% (78.125%)\n",
      "Epoch: [77][100/391]\tTime 0.044 (0.053)\tData 0.001 (0.010)\tLoss 0.6235 (0.6100)\tPrec 75.781% (78.512%)\n",
      "Epoch: [77][200/391]\tTime 0.043 (0.048)\tData 0.001 (0.006)\tLoss 0.4759 (0.6078)\tPrec 84.375% (78.817%)\n",
      "Epoch: [77][300/391]\tTime 0.044 (0.047)\tData 0.002 (0.004)\tLoss 0.5514 (0.6046)\tPrec 77.344% (78.769%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.256 (0.256)\tLoss 1.0393 (1.0393)\tPrec 67.188% (67.188%)\n",
      " * Prec 66.930% \n",
      "best acc: 66.980000\n",
      "Epoch: [78][0/391]\tTime 0.560 (0.560)\tData 0.509 (0.509)\tLoss 0.6410 (0.6410)\tPrec 78.906% (78.906%)\n",
      "Epoch: [78][100/391]\tTime 0.045 (0.050)\tData 0.002 (0.007)\tLoss 0.5844 (0.6003)\tPrec 78.906% (78.342%)\n",
      "Epoch: [78][200/391]\tTime 0.047 (0.048)\tData 0.002 (0.004)\tLoss 0.6819 (0.5976)\tPrec 78.906% (78.747%)\n",
      "Epoch: [78][300/391]\tTime 0.042 (0.047)\tData 0.002 (0.003)\tLoss 0.4922 (0.6016)\tPrec 82.812% (78.652%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.262 (0.262)\tLoss 1.1212 (1.1212)\tPrec 62.500% (62.500%)\n",
      " * Prec 65.950% \n",
      "best acc: 66.980000\n",
      "Epoch: [79][0/391]\tTime 0.636 (0.636)\tData 0.586 (0.586)\tLoss 0.5368 (0.5368)\tPrec 78.125% (78.125%)\n",
      "Epoch: [79][100/391]\tTime 0.043 (0.050)\tData 0.002 (0.007)\tLoss 0.5220 (0.5776)\tPrec 81.250% (79.394%)\n",
      "Epoch: [79][200/391]\tTime 0.044 (0.047)\tData 0.002 (0.004)\tLoss 0.5958 (0.5858)\tPrec 77.344% (79.097%)\n",
      "Epoch: [79][300/391]\tTime 0.044 (0.047)\tData 0.002 (0.004)\tLoss 0.6086 (0.5938)\tPrec 77.344% (78.841%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.356 (0.356)\tLoss 1.0048 (1.0048)\tPrec 71.094% (71.094%)\n",
      " * Prec 66.890% \n",
      "best acc: 66.980000\n",
      "Epoch: [80][0/391]\tTime 0.623 (0.623)\tData 0.574 (0.574)\tLoss 0.5286 (0.5286)\tPrec 81.250% (81.250%)\n",
      "Epoch: [80][100/391]\tTime 0.045 (0.051)\tData 0.002 (0.008)\tLoss 0.6161 (0.5877)\tPrec 75.781% (79.409%)\n",
      "Epoch: [80][200/391]\tTime 0.047 (0.048)\tData 0.002 (0.005)\tLoss 0.5698 (0.5915)\tPrec 77.344% (79.089%)\n",
      "Epoch: [80][300/391]\tTime 0.045 (0.047)\tData 0.002 (0.004)\tLoss 0.4682 (0.5919)\tPrec 84.375% (79.093%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.152 (0.152)\tLoss 0.9786 (0.9786)\tPrec 69.531% (69.531%)\n",
      " * Prec 66.230% \n",
      "best acc: 66.980000\n",
      "Epoch: [81][0/391]\tTime 0.921 (0.921)\tData 0.870 (0.870)\tLoss 0.6510 (0.6510)\tPrec 71.094% (71.094%)\n",
      "Epoch: [81][100/391]\tTime 0.043 (0.053)\tData 0.002 (0.010)\tLoss 0.6218 (0.5689)\tPrec 80.469% (80.128%)\n",
      "Epoch: [81][200/391]\tTime 0.043 (0.048)\tData 0.002 (0.006)\tLoss 0.6224 (0.5773)\tPrec 82.031% (79.699%)\n",
      "Epoch: [81][300/391]\tTime 0.042 (0.047)\tData 0.002 (0.005)\tLoss 0.5433 (0.5835)\tPrec 79.688% (79.402%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.244 (0.244)\tLoss 0.8990 (0.8990)\tPrec 73.438% (73.438%)\n",
      " * Prec 67.060% \n",
      "best acc: 67.060000\n",
      "Epoch: [82][0/391]\tTime 0.808 (0.808)\tData 0.756 (0.756)\tLoss 0.6159 (0.6159)\tPrec 74.219% (74.219%)\n",
      "Epoch: [82][100/391]\tTime 0.046 (0.053)\tData 0.002 (0.009)\tLoss 0.7155 (0.5783)\tPrec 74.219% (79.827%)\n",
      "Epoch: [82][200/391]\tTime 0.046 (0.049)\tData 0.002 (0.006)\tLoss 0.4478 (0.5798)\tPrec 85.156% (79.594%)\n",
      "Epoch: [82][300/391]\tTime 0.047 (0.047)\tData 0.002 (0.004)\tLoss 0.5228 (0.5816)\tPrec 80.469% (79.540%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.237 (0.237)\tLoss 1.0871 (1.0871)\tPrec 71.094% (71.094%)\n",
      " * Prec 66.200% \n",
      "best acc: 67.060000\n",
      "Epoch: [83][0/391]\tTime 0.913 (0.913)\tData 0.862 (0.862)\tLoss 0.4703 (0.4703)\tPrec 83.594% (83.594%)\n",
      "Epoch: [83][100/391]\tTime 0.044 (0.054)\tData 0.002 (0.010)\tLoss 0.7140 (0.5716)\tPrec 76.562% (79.997%)\n",
      "Epoch: [83][200/391]\tTime 0.048 (0.050)\tData 0.001 (0.006)\tLoss 0.5915 (0.5823)\tPrec 80.469% (79.478%)\n",
      "Epoch: [83][300/391]\tTime 0.049 (0.048)\tData 0.002 (0.005)\tLoss 0.3778 (0.5814)\tPrec 88.281% (79.591%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.644 (0.644)\tLoss 0.8618 (0.8618)\tPrec 72.656% (72.656%)\n",
      " * Prec 66.430% \n",
      "best acc: 67.060000\n",
      "Epoch: [84][0/391]\tTime 0.504 (0.504)\tData 0.457 (0.457)\tLoss 0.5581 (0.5581)\tPrec 82.812% (82.812%)\n",
      "Epoch: [84][100/391]\tTime 0.046 (0.049)\tData 0.002 (0.006)\tLoss 0.6319 (0.5770)\tPrec 78.125% (79.773%)\n",
      "Epoch: [84][200/391]\tTime 0.044 (0.047)\tData 0.002 (0.004)\tLoss 0.5930 (0.5746)\tPrec 78.125% (79.641%)\n",
      "Epoch: [84][300/391]\tTime 0.046 (0.047)\tData 0.001 (0.003)\tLoss 0.6089 (0.5752)\tPrec 78.125% (79.690%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.321 (0.321)\tLoss 0.9203 (0.9203)\tPrec 71.875% (71.875%)\n",
      " * Prec 66.800% \n",
      "best acc: 67.060000\n",
      "Epoch: [85][0/391]\tTime 0.481 (0.481)\tData 0.432 (0.432)\tLoss 0.6613 (0.6613)\tPrec 75.781% (75.781%)\n",
      "Epoch: [85][100/391]\tTime 0.044 (0.049)\tData 0.002 (0.006)\tLoss 0.6109 (0.5773)\tPrec 77.344% (79.571%)\n",
      "Epoch: [85][200/391]\tTime 0.048 (0.047)\tData 0.001 (0.004)\tLoss 0.5564 (0.5664)\tPrec 80.469% (79.894%)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 36\u001b[0m\n\u001b[1;32m     30\u001b[0m     os\u001b[38;5;241m.\u001b[39mmakedirs(fdir)\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m, epochs):\n\u001b[1;32m     34\u001b[0m     \u001b[38;5;66;03m#adjust_learning_rate(optimizer, epoch)\u001b[39;00m\n\u001b[0;32m---> 36\u001b[0m     \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrainloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     38\u001b[0m     \u001b[38;5;66;03m# evaluate on test set\u001b[39;00m\n\u001b[1;32m     39\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mValidation starts\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[1], line 91\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(trainloader, model, criterion, optimizer, epoch)\u001b[0m\n\u001b[1;32m     88\u001b[0m top1\u001b[38;5;241m.\u001b[39mupdate(prec\u001b[38;5;241m.\u001b[39mitem(), \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m))\n\u001b[1;32m     90\u001b[0m \u001b[38;5;66;03m# compute gradient and do SGD step\u001b[39;00m\n\u001b[0;32m---> 91\u001b[0m \u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mzero_grad\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     92\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m     93\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torch/_compile.py:24\u001b[0m, in \u001b[0;36m_disable_dynamo.<locals>.inner\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(fn)\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minner\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     22\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_dynamo\u001b[39;00m\n\u001b[0;32m---> 24\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dynamo\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdisable\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrecursive\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torch/_dynamo/eval_frame.py:489\u001b[0m, in \u001b[0;36m_TorchDynamoContext.__call__.<locals>._fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m     dynamo_config_ctx\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__enter__\u001b[39m()\n\u001b[1;32m    488\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 489\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    490\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    491\u001b[0m     set_eval_frame(prior)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torch/optim/optimizer.py:820\u001b[0m, in \u001b[0;36mOptimizer.zero_grad\u001b[0;34m(self, set_to_none)\u001b[0m\n\u001b[1;32m    818\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m p\u001b[38;5;241m.\u001b[39mgrad \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    819\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m set_to_none:\n\u001b[0;32m--> 820\u001b[0m         p\u001b[38;5;241m.\u001b[39mgrad \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    821\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    822\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m p\u001b[38;5;241m.\u001b[39mgrad\u001b[38;5;241m.\u001b[39mgrad_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# This cell won't be given, but students will complete the training\n",
    "\n",
    "lr = 2e-3\n",
    "weight_decay = 1e-6\n",
    "epochs = 200\n",
    "best_prec = 0\n",
    "\n",
    "#model = nn.DataParallel(model).cuda()\n",
    "model.cuda()\n",
    "criterion = nn.CrossEntropyLoss().cuda()\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "\n",
    "warmup_epochs = 5\n",
    "warmup_scheduler = torch.optim.lr_scheduler.LinearLR(\n",
    "    optimizer,\n",
    "    start_factor=0.1,\n",
    "    total_iters=warmup_epochs\n",
    ")\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(\n",
    "    optimizer,\n",
    "    T_max=epochs-warmup_epochs,\n",
    "    eta_min=1e-5\n",
    ")\n",
    "#cudnn.benchmark = True\n",
    "\n",
    "if not os.path.exists('result'):\n",
    "    os.makedirs('result')\n",
    "fdir = 'result/'+str(model_name)\n",
    "if not os.path.exists(fdir):\n",
    "    os.makedirs(fdir)\n",
    "        \n",
    "\n",
    "for epoch in range(0, epochs):\n",
    "    #adjust_learning_rate(optimizer, epoch)\n",
    "\n",
    "    train(trainloader, model, criterion, optimizer, epoch)\n",
    "    \n",
    "    # evaluate on test set\n",
    "    print(\"Validation starts\")\n",
    "    prec = validate(testloader, model, criterion)\n",
    "    \n",
    "    if epoch < warmup_epochs:\n",
    "        warmup_scheduler.step()\n",
    "    else:\n",
    "        scheduler.step()\n",
    "\n",
    "    # remember best precision and save checkpoint\n",
    "    is_best = prec > best_prec\n",
    "    best_prec = max(prec,best_prec)\n",
    "    print('best acc: {:1f}'.format(best_prec))\n",
    "    save_checkpoint({\n",
    "        'epoch': epoch + 1,\n",
    "        'state_dict': model.state_dict(),\n",
    "        'best_prec': best_prec,\n",
    "        'optimizer': optimizer.state_dict(),\n",
    "    }, is_best, fdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2da9fd4-3204-4e70-9788-6260637aff72",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = f\"result/{model_name}/model_best.pth.tar\"\n",
    "checkpoint = torch.load(PATH)\n",
    "model.load_state_dict(checkpoint['state_dict'])\n",
    "device = torch.device(\"cuda\") \n",
    "\n",
    "model.cuda()\n",
    "model.eval()\n",
    "\n",
    "test_loss = 0\n",
    "correct = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data, target in testloader:\n",
    "        data, target = data.to(device), target.to(device) # loading to GPU\n",
    "        output = model(data)\n",
    "        pred = output.argmax(dim=1, keepdim=True)  \n",
    "        correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "test_loss /= len(testloader.dataset)\n",
    "\n",
    "test_acc = 100. * correct / len(testloader.dataset)\n",
    "print('\\nTest set: Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        correct, len(testloader.dataset),\n",
    "        test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb6003b7-a73a-4f2f-88cf-81803593ecc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SaveOutput:\n",
    "    def __init__(self):\n",
    "        self.outputs = []\n",
    "    def __call__(self, module, module_in):\n",
    "        self.outputs.append(module_in)\n",
    "    def clear(self):\n",
    "        self.outputs = []  \n",
    "        \n",
    "######### Save inputs from squeezed layer ##########\n",
    "save_output = SaveOutput()\n",
    "model.features[27].register_forward_pre_hook(save_output) # input to squeezed layer\n",
    "model.features[28].register_forward_pre_hook(save_output) # input to relu layer\n",
    "model.features[29].register_forward_pre_hook(save_output) # input to next layer\n",
    "####################################################\n",
    "\n",
    "dataiter = iter(testloader)\n",
    "images, labels = next(dataiter)\n",
    "images = images.to(device)\n",
    "out = model(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9370025f-f905-43cb-8523-41bff669aa86",
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_q = model.features[27].weight_q\n",
    "w_alpha = model.features[27].weight_quant.wgt_alpha\n",
    "w_bit = 4\n",
    "\n",
    "weight_int = weight_q / (w_alpha / (2**(w_bit-1)-1))\n",
    "print(f\"Unique values in weight_int: {torch.unique(weight_int)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68a530e4-32df-433d-beed-e369800bdf8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "act = save_output.outputs[0][0]\n",
    "act_alpha  = model.features[27].act_alpha\n",
    "act_bit = 2\n",
    "act_quant_fn = act_quantization(act_bit)\n",
    "\n",
    "act_q = act_quant_fn(act, act_alpha)\n",
    "\n",
    "act_int = act_q / (act_alpha / (2**act_bit-1))\n",
    "print(f\"Unique values in act_int: {torch.unique(act_int)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7195f5e-a760-4721-93ab-c1a85692235e",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_int = torch.nn.Conv2d(in_channels = 16, out_channels=16, kernel_size = 3, padding=1)\n",
    "conv_int.weight = torch.nn.parameter.Parameter(weight_int)\n",
    "conv_int.bias = model.features[27].bias\n",
    "relu = torch.nn.ReLU(inplace=True)\n",
    "\n",
    "output_int = relu(conv_int(act_int))\n",
    "output_recovered = output_int * (act_alpha / (2**act_bit-1)) * (w_alpha / (2**(w_bit-1)-1))\n",
    "#print(output_recovered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c26c227a-5704-4ca8-a447-9fcfc6d810fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "difference = output_recovered - save_output.outputs[2][0]\n",
    "error = difference.abs().mean()\n",
    "# error = torch.norm(difference) # L2 Norm\n",
    "if error < 1e-3 and test_acc > 90:\n",
    "    print(\"Part 2.1: PASS\")\n",
    "    print(f\"Error = {error}\")\n",
    "    print(f\"Test Acc = {test_acc}\")\n",
    "else:\n",
    "    print(\"Part 2.1: FAIL\")\n",
    "    print(f\"Error = {error}\")\n",
    "    print(f\"Test Acc = {test_acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d94f27c9-f7a8-4f84-86a5-834865ac42aa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
